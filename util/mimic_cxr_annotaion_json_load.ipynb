{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON 파일 관리를 위해서 excel 변환\n",
    "* 해당 JSON은 MIMIC-CXR을 GPT4V를 통해서 Annotation를 만들어서 VQA 형태의 JSON 파일을 만든 데이터셋으로 아래 링크 참고.\n",
    "https://physionet.org/content/llava-rad-mimic-cxr-annotation/1.0.0/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엑셀 파일 변환 완료: output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open(\"C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_test_MIMIC_CXR_all_gpt4extract_rulebased_v1.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 데이터프레임을 위한 리스트\n",
    "records = []\n",
    "\n",
    "for entry in data:\n",
    "    image_download_path = entry.get(\"image\").replace(\"mimic\", \"files\")\n",
    "    image_path = entry.get(\"image\")\n",
    "    image_url = f\"https://physionet.org/files/mimic-cxr-jpg/2.0.0/{image_download_path}\"\n",
    "    image_script = f\"wget --no-parent --no-directories -N -c --user jeayoung --password 'okok!!8462' -P ./{os.path.dirname(image_path)} \\\"{image_url}\\\"\"\n",
    "    \n",
    "    # Report URL 생성\n",
    "    report_download_folder = os.path.dirname(image_download_path)\n",
    "    report_folder = os.path.dirname(image_path)\n",
    "    report_url = f\"https://physionet.org/files/mimic-cxr/2.1.0/{report_download_folder}.txt\"\n",
    "    report_script = f\"wget --no-parent --no-directories -N -c --user jeayoung --password 'okok!!8462' -P ./{report_folder} \\\"{report_url}\\\"\"\n",
    "    \n",
    "    record = {\n",
    "        \"id\": entry.get(\"id\"),\n",
    "        \"image_script\": image_script,\n",
    "        \"report_script\": report_script,\n",
    "        \"image\": entry.get(\"image\"),\n",
    "        \"generate_method\": entry.get(\"generate_method\"),\n",
    "        \"reason\": entry.get(\"reason\"),\n",
    "        \"impression\": entry.get(\"impression\"),\n",
    "        \"indication\": entry.get(\"indication\"),\n",
    "        \"history\": entry.get(\"history\"),\n",
    "        \"view\": entry.get(\"view\"),\n",
    "        \"orientation\": entry.get(\"orientation\"),\n",
    "    }\n",
    "    \n",
    "    # Chexpert Labels 추가\n",
    "    chexpert_labels = entry.get(\"chexpert_labels\", {})\n",
    "    for label, value in chexpert_labels.items():\n",
    "        record[label] = value\n",
    "    \n",
    "    # Conversations에서 human 및 gpt 값 추출 (줄바꿈 유지)\n",
    "    human_value = next((conv[\"value\"].encode(\"unicode_escape\").decode(\"utf-8\") for conv in entry.get(\"conversations\", []) if conv[\"from\"] == \"human\"), None)\n",
    "    gpt_value = next((conv[\"value\"].encode(\"unicode_escape\").decode(\"utf-8\") for conv in entry.get(\"conversations\", []) if conv[\"from\"] == \"gpt\"), None)\n",
    "    \n",
    "    record[\"human_value\"] = human_value\n",
    "    record[\"gpt_value\"] = gpt_value\n",
    "    \n",
    "    # JSON 전체 문자열 (엔터 제거)\n",
    "    record[\"json_string\"] = json.dumps(entry, separators=(\",\", \":\"))\n",
    "    \n",
    "    records.append(record)\n",
    "\n",
    "# Pandas 데이터프레임 변환\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 엑셀로 저장\n",
    "df.to_excel(\"C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_test_MIMIC_CXR_all_gpt4extract_rulebased_v1.xlsx\", index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(\"엑셀 파일 변환 완료: output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_1.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_2.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_3.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_4.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_5.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_6.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_7.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_8.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_9.xlsx\n",
      "엑셀 파일 저장 완료: C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_10.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open(\"C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "# 데이터프레임을 위한 리스트\n",
    "records = []\n",
    "\n",
    "for entry in data:\n",
    "    image_download_path = entry.get(\"image\").replace(\"mimic\", \"files\")\n",
    "    image_path = entry.get(\"image\")\n",
    "    image_url = f\"https://physionet.org/files/mimic-cxr-jpg/2.0.0/{image_download_path}\"\n",
    "    image_script = f\"wget --no-parent --no-directories -N -c --user jeayoung --password 'okok!!8462' -P ./{os.path.dirname(image_path)} \\\"{image_url}\\\"\"\n",
    "    \n",
    "    # Report URL 생성\n",
    "    report_download_folder = os.path.dirname(image_download_path)\n",
    "    report_folder = os.path.dirname(image_path)\n",
    "    report_url = f\"https://physionet.org/files/mimic-cxr/2.1.0/{report_download_folder}.txt\"\n",
    "    report_script = f\"wget --no-parent --no-directories -N -c --user jeayoung --password 'okok!!8462' -P ./{report_folder} \\\"{report_url}\\\"\"\n",
    "    \n",
    "    record = {\n",
    "        \"id\": entry.get(\"id\"),\n",
    "        \"image_script\": image_script,\n",
    "        \"report_script\": report_script,\n",
    "        \"image\": entry.get(\"image\"),\n",
    "        \"generate_method\": entry.get(\"generate_method\"),\n",
    "        \"reason\": entry.get(\"reason\"),\n",
    "        \"impression\": entry.get(\"impression\"),\n",
    "        \"indication\": entry.get(\"indication\"),\n",
    "        \"history\": entry.get(\"history\"),\n",
    "        \"view\": entry.get(\"view\"),\n",
    "        \"orientation\": entry.get(\"orientation\"),\n",
    "    }\n",
    "    \n",
    "    # Chexpert Labels 추가\n",
    "    chexpert_labels = entry.get(\"chexpert_labels\", {})\n",
    "    for label, value in chexpert_labels.items():\n",
    "        record[label] = value\n",
    "    \n",
    "    # Conversations에서 human 및 gpt 값 추출 (줄바꿈 유지)\n",
    "    human_value = next((conv[\"value\"].encode(\"unicode_escape\").decode(\"utf-8\") for conv in entry.get(\"conversations\", []) if conv[\"from\"] == \"human\"), None)\n",
    "    gpt_value = next((conv[\"value\"].encode(\"unicode_escape\").decode(\"utf-8\") for conv in entry.get(\"conversations\", []) if conv[\"from\"] == \"gpt\"), None)\n",
    "    \n",
    "    record[\"human_value\"] = human_value\n",
    "    record[\"gpt_value\"] = gpt_value\n",
    "    \n",
    "    # JSON 전체 문자열 (엔터 제거)\n",
    "    record[\"json_string\"] = json.dumps(entry, separators=(\",\", \":\"))\n",
    "    \n",
    "    records.append(record)\n",
    "\n",
    "# Pandas 데이터프레임 변환\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 파일 분할 저장 (10개로 나누기)\n",
    "num_files = 10\n",
    "chunk_size = len(df) // num_files + (len(df) % num_files > 0)\n",
    "\n",
    "\n",
    "for i in range(num_files):\n",
    "    chunk_df = df[i * chunk_size:(i + 1) * chunk_size]\n",
    "    file_path = os.path.join(f\"C:/DEV/01. workspace/LLaVA-Med-RAG/data/mimic_cxr_annotaion_json/chat_train_MIMIC_CXR_all_gpt4extract_rulebased_v1_{i+1}.xlsx\")\n",
    "    chunk_df.to_excel(file_path, index=False, engine=\"openpyxl\")\n",
    "    print(f\"엑셀 파일 저장 완료: {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
